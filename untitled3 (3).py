# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16wQwjTQosrilQKlgHcYbMPkyDJL-dE9s
"""

from google.colab import drive
drive.mount('/content/drive')

import zipfile

# Path to the ZIP file on Google Drive
zip_path = '/content/drive/MyDrive/amazon.csv.zip'
extract_to = '/content/drive/MyDrive/'  # Directory to extract files

# Unzipping the file
with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_to)

print("Files unzipped successfully!")

import os
print(os.listdir(extract_to))

import pandas as pd

# Load CSV files into DataFrames
df = pd.read_csv(f'{extract_to}/amazon.csv')

df.info()

df.head(3)

df['rating_count'].isnull().sum()

# Clean the 'rating_count' column
df['rating_count'] = df['rating_count'].replace({',': ''}, regex=True)

# Convert the column to numeric (float), as the mean will be a float
df['rating_count'] = pd.to_numeric(df['rating_count'], errors='coerce')

# Fill missing values with the mean of the column
median_rating_count = df['rating_count'].median()
df['rating_count'] = df['rating_count'].fillna(median_rating_count)

# Convert the 'rating_count' column to int
df['rating_count'] = df['rating_count'].astype(int)

# Clean and convert the columns to numeric
df['discounted_price'] = df['discounted_price'].replace({'₹': '', ',': ''}, regex=True).astype(float)
df['actual_price'] = df['actual_price'].replace({'₹': '', ',': ''}, regex=True).astype(float)
df['discount_percentage'] = df['discount_percentage'].replace({'%': '', ',': ''}, regex=True).astype(float)
df['rating'] = pd.to_numeric(df['rating'], errors='coerce')  # Coerce errors if any invalid values are found

df['rating_count'].isnull().sum()

df['category'].unique()

df['category'] = df['category'].astype(str)

import pandas as pd
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.feature_extraction.text import TfidfVectorizer

# Preprocess text columns: product_name, about_product

# Preprocessing function for text columns (product_name and about_product)
def preprocess_text(text):
    text = text.lower()  # Lowercase text
    return text  # Return as is, no need for spaCy (TF-IDF will handle tokenization)

df['product_name'] = df['product_name'].apply(preprocess_text)
df['about_product'] = df['about_product'].apply(preprocess_text)

# Preprocess categorical column: category (multi-label)
mlb = MultiLabelBinarizer()

# Assuming 'category' is a column with categories separated by pipe ('|')
df['category'] = df['category'].apply(lambda x: x.split('|'))  # Split categories by pipe

# Apply MultiLabelBinarizer to the 'category' column
category_binarized = mlb.fit_transform(df['category'])
category_df = pd.DataFrame(category_binarized, columns=mlb.classes_, index=df.index)

# Concatenate the new binary columns for categories with the original dataframe
df = pd.concat([df, category_df], axis=1)

# Drop the original 'category' column after binarization
df = df.drop('category', axis=1)

# Preprocess numeric columns: rating, rating_count
df['rating'] = pd.to_numeric(df['rating'], errors='coerce')  # Convert to numeric, invalid entries become NaN
# Remove commas and any special characters, ensuring only numeric values remain
df['rating_count'] = df['rating_count'].replace({',': '', '[^\d.]': ''}, regex=True)

# Convert to numeric, invalid entries become NaN
df['rating_count'] = pd.to_numeric(df['rating_count'], errors='coerce')

# Vectorize text columns for Content-Based Filtering (using TF-IDF)
tfidf_vectorizer = TfidfVectorizer(stop_words='english')
df['product_name_tfidf'] = list(tfidf_vectorizer.fit_transform(df['product_name']).toarray())
df['about_product_tfidf'] = list(tfidf_vectorizer.fit_transform(df['about_product']).toarray())

from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# Use the precomputed TF-IDF vectors
product_name_tfidf = np.array(df['product_name_tfidf'].tolist())
about_product_tfidf = np.array(df['about_product_tfidf'].tolist())

# Calculate Cosine Similarity for product descriptions
cosine_sim_name = cosine_similarity(product_name_tfidf)
cosine_sim_about = cosine_similarity(about_product_tfidf)

# Combine the similarities with optional weighting
cosine_sim = 0.6 * cosine_sim_name + 0.4 * cosine_sim_about  # Adjust weights as necessary

from scipy.spatial.distance import cdist
from scipy.sparse import csr_matrix

# Convert to sparse matrix and ensure it's 2D
sparse_category_binarized = csr_matrix(category_binarized)

# Calculate the Jaccard similarity using cdist
category_sim = 1 - cdist(sparse_category_binarized.toarray(), sparse_category_binarized.toarray(), metric='jaccard')

# Step 1: Compute initial similarity matrices (you have already done this part)

# Assuming you already have:
# - cosine_sim for product_name similarity
# - category_sim for category similarity

# Example: cosine_sim and category_sim matrices are already computed
# You should already have 'cosine_sim' and 'category_sim' matrices here

# Step 2: Grid Search to fine-tune weights

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import make_scorer
import numpy as np

# Function to compute combined similarity with given weights
def compute_combined_similarity(cosine_sim, category_sim, weight_cosine=0.5, weight_category=0.5):
    return weight_cosine * cosine_sim + weight_category * category_sim

# Define a custom scoring function (Mean Squared Error or other evaluation metric)
def custom_scorer(y_true, y_pred):
    # Mean Squared Error (MSE) between actual and predicted relevance/ratings
    return np.mean((y_true - y_pred) ** 2)  # You can use RMSE or other metrics if needed

# Define the parameter grid to search for the best weights
param_grid = {
    'weight_cosine': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],  # Possible weight for cosine similarity
    'weight_category': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]  # Possible weight for category similarity
}

# Instead of using GridSearchCV directly, we'll manually iterate through the grid:
best_score = float('inf')  # Initialize with a very large value
best_params = {}

for weight_cosine in param_grid['weight_cosine']:
    for weight_category in param_grid['weight_category']:
        # Compute combined similarity with current weights
        combined_sim = compute_combined_similarity(cosine_sim, category_sim, weight_cosine, weight_category)

        # Here, you would need to have some ground truth data (y_true) to evaluate the similarity matrix
        # For example, if you have user ratings, you can use them as y_true
        # and use combined_sim to predict ratings and then calculate the score.

        # Replace this with your actual evaluation logic:
        # score = custom_scorer(y_true, predicted_ratings_using_combined_sim)

        # Example using a dummy score (replace with your actual evaluation)
        score = np.mean(np.abs(combined_sim - cosine_sim)) # Example score calculation

        # Update best score and parameters if current combination is better
        if score < best_score:
            best_score = score
            best_params = {'weight_cosine': weight_cosine, 'weight_category': weight_category}

print(f"Best Weight for Cosine Similarity: {best_params['weight_cosine']}")
print(f"Best Weight for Category Similarity: {best_params['weight_category']}")

# Step 3: Compute the final combined similarity matrix using the best weights
final_sim = compute_combined_similarity(cosine_sim, category_sim, weight_cosine=best_params['weight_cosine'], weight_category=best_params['weight_category'])

# Step 4: Use the final similarity matrix for product recommendations or further evaluation

from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# Convert TF-IDF stored lists back to numpy arrays
product_name_tfidf = np.array(df['product_name_tfidf'].tolist())  # TF-IDF vectors for product names
about_product_tfidf = np.array(df['about_product_tfidf'].tolist())  # TF-IDF vectors for product descriptions

# Compute Cosine Similarities
cosine_sim_name = cosine_similarity(product_name_tfidf)  # Similarity based on product names
cosine_sim_about = cosine_similarity(about_product_tfidf)  # Similarity based on descriptions

# Compute Final Similarity Matrix with Weights
final_sim = (0.8 * cosine_sim_name) + (0.1 * cosine_sim_about)  # Optimized Weights

print("Final Content-Based Similarity Matrix Computed Successfully!")

def get_recommendations(product_id, final_sim, df, top_n=5):
    # Get the index of the product
    product_idx = df[df['product_id'] == product_id].index[0]

    # Get similarity scores for all products
    sim_scores = list(enumerate(final_sim[product_idx]))

    # Sort products by similarity score (excluding itself)
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:top_n+1]

    # Get product indices
    product_indices = [i[0] for i in sim_scores]

    # Return top N recommended products
    return df.iloc[product_indices][['product_id', 'product_name']]

# Example Usage:
recommended_products = get_recommendations('B0BQRJ3C47', final_sim, df, top_n=5)
print(recommended_products)

print(df.columns)

import pandas as pd
import numpy as np
from sklearn.metrics import mean_squared_error

user_ratings = df[['user_id', 'product_id', 'rating']].dropna()


def evaluate_rmse(df, final_sim, user_ratings):
    actual_ratings = []
    predicted_ratings = []

    for index, row in user_ratings.iterrows():
        product_id = row['product_id']
        actual_rating = row['rating']  # Ground truth rating

        # Get product index
        if product_id not in df['product_id'].values:
            continue  # Skip if product ID is not in the dataset

        product_idx = df[df['product_id'] == product_id].index[0]

        # Predict rating using similarity scores (average of top 5 similar items)
        sim_scores = list(enumerate(final_sim[product_idx]))
        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:6]  # Top 5

        sim_indices = [i[0] for i in sim_scores]

        predicted_rating = np.mean([
            user_ratings[user_ratings['product_id'] == df.iloc[i]['product_id']]['rating'].mean()
            for i in sim_indices if df.iloc[i]['product_id'] in user_ratings['product_id'].values
        ])

        if not np.isnan(predicted_rating):
            actual_ratings.append(actual_rating)
            predicted_ratings.append(predicted_rating)

    # Compute RMSE
    if len(actual_ratings) == 0 or len(predicted_ratings) == 0:
        print("Not enough data to calculate RMSE")
        return None

    rmse = np.sqrt(mean_squared_error(actual_ratings, predicted_ratings))
    print(f"RMSE: {rmse}")
    return rmse

# Example usage
rmse_score = evaluate_rmse(df, final_sim, user_ratings)

!pip install scikit-surprise

import pandas as pd
import numpy as np
from surprise import SVD
from surprise import Dataset, Reader
from surprise.model_selection import train_test_split
from surprise import accuracy

df['user_id'] = df['user_id'].astype(str)
df['product_id'] = df['product_id'].astype(str)


# Select relevant columns (assuming 'user_id', 'product_id', and 'rating' exist)
df = df[['user_id', 'product_id', 'rating']]

# Convert the data into Surprise format
reader = Reader(rating_scale=(df['rating'].min(), df['rating'].max()))
data = Dataset.load_from_df(df[['user_id', 'product_id', 'rating']], reader)

# Split into train and test sets
trainset, testset = train_test_split(data, test_size=0.2, random_state=42)

# Train SVD model
model = SVD(n_factors=50, random_state=42)
model.fit(trainset)

# Evaluate on the test set
predictions = model.test(testset)
rmse = accuracy.rmse(predictions)
print(f"RMSE: {rmse:.4f}")

# Function to recommend top N products for a user
def recommend_products(user_id, model, df, n=5):
    all_products = df['product_id'].unique()
    user_rated_products = df[df['user_id'] == user_id]['product_id'].tolist()

    # Predict ratings for unrated products
    predictions = [model.predict(user_id, pid) for pid in all_products if pid not in user_rated_products]

    # Sort by predicted rating
    top_products = sorted(predictions, key=lambda x: x.est, reverse=True)[:n]
    return [(p.iid, p.est) for p in top_products]

# Example: Recommend products for a specific user
user_id = "some_user_id"  # Replace with an actual user_id
recommendations = recommend_products(user_id, model, df, n=5)
print("Top Recommendations:", recommendations)

import pandas as pd
import numpy as np
from surprise import SVD
from surprise import Dataset, Reader
from surprise.model_selection import train_test_split
from surprise import accuracy

# Ensure 'user_id' and 'product_id' are strings (avoids errors)
df['user_id'] = df['user_id'].astype(str)
df['product_id'] = df['product_id'].astype(str)

# Select relevant columns
df = df[['user_id', 'product_id', 'rating']]

# Define reader with dynamic rating range
reader = Reader(rating_scale=(df['rating'].min(), df['rating'].max()))

# Convert the data into Surprise format
data = Dataset.load_from_df(df[['user_id', 'product_id', 'rating']], reader)

# Split into train and test sets
trainset, testset = train_test_split(data, test_size=0.2, random_state=42)

# Train SVD model
model = SVD(n_factors=50, random_state=42)
model.fit(trainset)

# Evaluate on the test set
predictions = model.test(testset)
rmse = accuracy.rmse(predictions)
print(f"RMSE: {rmse:.4f}")

# Function to recommend top N products for a user
def recommend_products(user_id, model, df, n=5):
    all_products = df['product_id'].unique()
    user_rated_products = df[df['user_id'] == user_id]['product_id'].tolist()

    # Predict ratings for unrated products
    predictions = [model.predict(user_id, pid) for pid in all_products if pid not in user_rated_products]

    # Sort by predicted rating
    top_products = sorted(predictions, key=lambda x: x.est, reverse=True)[:n]
    return [(p.iid, p.est) for p in top_products]

# Example: Recommend products for a specific user
user_id = df['user_id'].iloc[0]  # Select an actual user_id from the dataset
recommendations = recommend_products(user_id, model, df, n=5)
print("Top Recommendations:", recommendations)

import pandas as pd
from sklearn.metrics import precision_score, recall_score, f1_score

# Example: Dataframe with actual interactions and model predictions
# Let's say 'user_interaction' is the actual ground truth (1 for interaction, 0 for no interaction)
# and 'model_recommendation' is the prediction (1 for predicted interaction, 0 for no interaction)
data = {
    'product_id': [101, 102, 103, 104, 105],  # Example product IDs
    'user_interaction': [1, 0, 1, 0, 1],      # Actual user interactions
    'model_recommendation': [1, 1, 0, 0, 1]   # Predicted interactions (model output)
}

# Convert to DataFrame
df = pd.DataFrame(data)

# Define ground truth and predictions
ground_truth = df['user_interaction']
predictions = df['model_recommendation']

# Calculate precision, recall, and F1-score
precision = precision_score(ground_truth, predictions)
recall = recall_score(ground_truth, predictions)
f1 = f1_score(ground_truth, predictions)

# Print the results
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1:.4f}")

from sklearn.metrics import precision_recall_fscore_support, accuracy_score

# Convert ratings into discrete classes (e.g., Low: 1-2, Medium: 3, High: 4-5)
def categorize_ratings(rating):
    if rating <= 2.0:
        return 0  # Low Rating
    elif rating == 3.0:
        return 1  # Medium Rating
    else:
        return 2  # High Rating

# Convert y_true and y_pred into categories
y_true_categorized = [categorize_ratings(r) for r in y_true]
y_pred_categorized = [categorize_ratings(r) for r in y_pred]

# Compute precision, recall, F1-score, and support
precision, recall, f1, support = precision_recall_fscore_support(y_true_categorized, y_pred_categorized, average='weighted')

# Compute accuracy
accuracy = accuracy_score(y_true_categorized, y_pred_categorized)

# Print metrics
print(f'Precision: {precision:.4f}')
print(f'Recall: {recall:.4f}')
print(f'F1 Score: {f1:.4f}')
print(f'Accuracy: {accuracy:.4f}')